## Опис проєкту
Парсер та індексатор контенту з мережі інтернет. Маленький Гугол, який індексує вебсторінки і не тільки.

Вимоги до кандидата:
Знання Python, вміння працювати с багатопотоковими застосунками, вміння працювати з чергами завдань (celery). Знайомство з фреймворком Flask. Досвід роботи с SQL, базами даних. На проєкті використовується ClickHouse як основне сховище даних, у якому досить багато даних.  Тому необхідно вміння створювати багаторівневі запити, потрібно розуміти в чому різниця між різними join (inner, left, right, outer, not, …), принцип роботи різних типів view та різних storage engine. Потрібно робити точні та швидкі вибірки даних з багатьох таблиць одночасно, завчасно додаючи індекси де потрібно.

Базове знання фронтенду буде плюсом (в нас є також адмін панель для користувачів)

Знання Linux, вміння використовувати docker та docker-compose для запуску nginx, unicorn etc.

Загалом потрібно розуміти як робити багатопотокові програми які працюють по списку задач с можливою пріоритизацією. Потрібно збирати та підготовлюють велику кількість даних для запису в базу даних.

Розуміння як працювати з Playwrigth буде плюсом, бо зазвичай новітні сайти не полюбляють коли їх скраппять, та протидіють цьому, и headless браузеры допомагають нам працювати з такими застосунками.

Приклади завдань: додати обробку матеріалів з порталу pravda.ua для іх індексації та пошуку ключових запитів з доданих до налаштувать проектів моніторингу.
Приклади завдань: переробити існуючі модулі проєкту для запуску в незалежних контейнерах. Перейти на використання Redis як черги задач для розподілення завдань поміж контейнерами.